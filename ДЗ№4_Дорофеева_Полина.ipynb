{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В этом практикуме мы рассмотрим работу с библиотекой **Gensim** для работы с векторными представлениями текста\n",
        "\n",
        "Мы рассмотрим\n",
        "- **Word2Vec** - векторные представления слов\n",
        "- **FastText** - улучшенные представления с учетом морфологии  \n",
        "- **Doc2Vec** - векторные представления документов\n"
      ],
      "metadata": {
        "id": "N4SYal7iVHxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, FastText, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bolJ-w-oVVZZ",
        "outputId": "84d3710c-5fa6-4d95-d452-eb47ba9ee407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1: Word2Vec\n",
        "\n",
        "### Что такое Word2Vec?\n",
        "\n",
        "Word2Vec преобразует слова в векторы чисел так, что семантически похожие слова оказываются близко в векторном пространстве.\n",
        "\n",
        "**Два основных алгоритма:**\n",
        "- **CBOW** - предсказывает слово по контексту\n",
        "- **Skip-gram** - предсказывает контекст по слову\n",
        "\n",
        "**Загрузка предобученной модели**"
      ],
      "metadata": {
        "id": "vB663h2uXJE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m2YjiqkVVmd",
        "outputId": "fa30af7f-504b-45b8-fea9-e808f271f169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Размер словаря: 400000\n",
            "Размерность векторов: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите документацию `gensim`: какие датасеты кроме `glove-wiki-gigaword-100` доступны в библиотеке?\n",
        "\n",
        "Выберите 3 датасета и кратко опишите их (источник данных, примерный объем, зачем такой датасет может использоваться)"
      ],
      "metadata": {
        "id": "VDOPbPZCXQJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Базовые операции с векторами**"
      ],
      "metadata": {
        "id": "eib9fIpIXp3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор слова\n",
        "vector = w2v_model['computer']\n",
        "print(f\"Вектор слова 'computer': {vector[:5]}...\")  # Показываем первые 5 чисел\n",
        "\n",
        "# Вычисляем схожесть между словами\n",
        "similarity = w2v_model.similarity('computer', 'laptop')\n",
        "print(f\"Схожесть 'computer' и 'laptop': {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9fBjDYNXoUO",
        "outputId": "5258794b-a1f4-45c1-a775-680a836a0bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор слова 'computer': [-0.16298   0.30141   0.57978   0.066548  0.45835 ]...\n",
            "Схожесть 'computer' и 'laptop': 0.7024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Поиск похожих слов**"
      ],
      "metadata": {
        "id": "Ev1yMPZ8XuI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Находим похожие слова\n",
        "similar_words = w2v_model.most_similar('python', topn=5)\n",
        "print(\"Слова, похожие на 'python':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"  {word}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "8WkxOy8uXteF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Ваш ответ здесь*"
      ],
      "metadata": {
        "id": "AKeYJM6IXgVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "1. Загрузите любой датасет из gensim на ваш выбор"
      ],
      "metadata": {
        "id": "TM76pHnKXi_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "# 1. Посмотрим список доступных датасетов\n",
        "print(\"Доступные датасеты в gensim:\")\n",
        "datasets = list(api.info()['models'].keys())\n",
        "for i, dataset in enumerate(datasets[:10], 1):  # Покажем первые 10\n",
        "    print(f\"  {i}. {dataset}\")\n",
        "if len(datasets) > 10:\n",
        "    print(f\"  ... и еще {len(datasets) - 10} датасетов\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 2. Выберем датасет 'glove-twitter-25'\n",
        "print(\"Загружаю датасет 'glove-twitter-25'...\")\n",
        "try:\n",
        "    model = api.load('glove-twitter-25')\n",
        "    print(\"Датасет успешно загружен!\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке: {e}\")\n",
        "    print(\"\\nПробую загрузить другой датасет...\")\n",
        "    # Попробуем самый маленький\n",
        "    model = api.load('text8')  # text8 - очень маленький корпус для тестов\n",
        "\n",
        "print(f\"Тип объекта: {type(model)}\")\n",
        "print(f\"Размер словаря: {len(model)} слов\")\n",
        "if hasattr(model, 'vector_size'):\n",
        "    print(f\"Размерность векторов: {model.vector_size}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 3. Проверим, что можем работать с данными\n",
        "if hasattr(model, 'most_similar'):\n",
        "    test_words = ['apple', 'cat', 'good', 'computer', 'run']\n",
        "\n",
        "    for word in test_words:\n",
        "        if word in model:\n",
        "            print(f\"Найдено похожих слов для '{word}':\")\n",
        "            try:\n",
        "                similar_words = model.most_similar(word, topn=3)\n",
        "                for w, sim in similar_words:\n",
        "                    print(f\"  - {w}: {sim:.3f}\")\n",
        "                print()\n",
        "            except Exception as e:\n",
        "                print(f\"  Ошибка: {e}\")\n",
        "        else:\n",
        "            print(f\"Слово '{word}' отсутствует в словаре\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "pqblXXpmXOhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e08246e-019a-47b3-9d63-bf4af1c4012f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Доступные датасеты в gensim:\n",
            "  1. fasttext-wiki-news-subwords-300\n",
            "  2. conceptnet-numberbatch-17-06-300\n",
            "  3. word2vec-ruscorpora-300\n",
            "  4. word2vec-google-news-300\n",
            "  5. glove-wiki-gigaword-50\n",
            "  6. glove-wiki-gigaword-100\n",
            "  7. glove-wiki-gigaword-200\n",
            "  8. glove-wiki-gigaword-300\n",
            "  9. glove-twitter-25\n",
            "  10. glove-twitter-50\n",
            "  ... и еще 3 датасетов\n",
            "\n",
            "==================================================\n",
            "\n",
            "Загружаю датасет 'glove-twitter-25'...\n",
            "Датасет успешно загружен!\n",
            "Тип объекта: <class 'gensim.models.keyedvectors.KeyedVectors'>\n",
            "Размер словаря: 1193514 слов\n",
            "Размерность векторов: 25\n",
            "\n",
            "==================================================\n",
            "\n",
            "Найдено похожих слов для 'apple':\n",
            "  - windows: 0.895\n",
            "  - microsoft: 0.886\n",
            "  - google: 0.882\n",
            "\n",
            "Найдено похожих слов для 'cat':\n",
            "  - dog: 0.959\n",
            "  - monkey: 0.920\n",
            "  - bear: 0.914\n",
            "\n",
            "Найдено похожих слов для 'good':\n",
            "  - too: 0.965\n",
            "  - day: 0.953\n",
            "  - well: 0.950\n",
            "\n",
            "Найдено похожих слов для 'computer':\n",
            "  - camera: 0.908\n",
            "  - cell: 0.892\n",
            "  - server: 0.874\n",
            "\n",
            "Найдено похожих слов для 'run':\n",
            "  - down: 0.970\n",
            "  - up: 0.958\n",
            "  - out: 0.951\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Напишите функцию, которая принимает на вход любое слово и вовращает 10 наиболее близких по вектору слов"
      ],
      "metadata": {
        "id": "vr2jwkoYXw4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Загружаем один раз\n",
        "model = api.load('glove-twitter-25')\n",
        "\n",
        "def похожие_слова(слово, n=10):\n",
        "    \"\"\"Простая функция для поиска похожих слов\"\"\"\n",
        "    if слово in model:\n",
        "        return model.most_similar(слово, topn=n)\n",
        "    return []\n",
        "\n",
        "# Используем\n",
        "print(\"Похожие на 'cat':\")\n",
        "for w, s in похожие_слова(\"cat\", 5):\n",
        "    print(f\"{w} - {s:.3f}\")"
      ],
      "metadata": {
        "id": "41PPnrrtX7lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ad3662-bb10-42dd-f0ec-170c5addf08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Похожие на 'cat':\n",
            "dog - 0.959\n",
            "monkey - 0.920\n",
            "bear - 0.914\n",
            "pet - 0.911\n",
            "girl - 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Обучите модель Word2Vec на тестовом датасете из ячейки ниже\n",
        "\n",
        "Примените следующие настройки:\n",
        "\n",
        "- размер вектора: 50\n",
        "- размер окна: 3\n",
        "- минимальная частота слова: 1\n",
        "- потоков: 2\n",
        "- использовать skip-gram"
      ],
      "metadata": {
        "id": "kqb9gAAtX-2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cooking_sentences = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]"
      ],
      "metadata": {
        "id": "Hx2_76jlX99p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Наши предложения про готовку\n",
        "рецепты = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "print(\"Создаю модель Word2Vec для анализа кулинарных текстов...\")\n",
        "модель = Word2Vec(\n",
        "    sentences=рецепты,    # наши тексты\n",
        "    vector_size=50,       # размер вектора слова\n",
        "    window=3,             # смотрим на 3 слова вокруг\n",
        "    min_count=1,          # берем все слова\n",
        "    workers=2,            # два потока\n",
        "    sg=1                  # алгоритм skip-gram\n",
        ")\n",
        "\n",
        "print(\"Готово! Модель обучена.\")\n",
        "print(f\"В словаре {len(модель.wv)} кулинарных слов\")\n",
        "print()\n",
        "\n",
        "# Смотрим, какие слова есть в словаре\n",
        "print(\"Слова из наших рецептов:\")\n",
        "слова = list(модель.wv.key_to_index.keys())\n",
        "for слово in слова:\n",
        "    print(f\"• {слово}\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Ищем похожие слова\n",
        "print(\"А теперь посмотрим на семантические связи:\")\n",
        "\n",
        "# Проверяем для глаголов готовки\n",
        "глаголы = ['варить', 'жарить', 'резать', 'печь']\n",
        "\n",
        "for глагол in глаголы:\n",
        "    if глагол in модель.wv:\n",
        "        print(f\"\\nЧто похоже на '{глагол}'?\")\n",
        "        похожие = модель.wv.most_similar(глагол, topn=3)\n",
        "\n",
        "        for слово, близость in похожие:\n",
        "            # Преобразуем в проценты для наглядности\n",
        "            проценты = близость * 100\n",
        "            print(f\"  {слово} ({проценты:.1f}% схожести)\")\n",
        "    else:\n",
        "        print(f\"\\nСлово '{глагол}' не нашлось в текстах\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Сравниваем пары слов\n",
        "print(\"Сравним некоторые слова:\")\n",
        "\n",
        "пары = [\n",
        "    ('суп', 'салат'),\n",
        "    ('духовка', 'сковорода'),\n",
        "    ('овощи', 'фрукты')\n",
        "]\n",
        "\n",
        "for слово1, слово2 in пары:\n",
        "    if слово1 in модель.wv and слово2 in модель.wv:\n",
        "        схожесть = модель.wv.similarity(слово1, слово2)\n",
        "        # Оценка от 0 до 1, где 1 - очень похожи\n",
        "        print(f\"  {слово1} и {слово2}: {схожесть:.2f}\")\n",
        "    else:\n",
        "        print(f\"  {слово1} и {слово2}: не можем сравнить\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Покажем векторы слов\n",
        "print(\"Векторное представление слов (первые 5 значений):\")\n",
        "примерные_слова = ['суп', 'овощи', 'духовка']\n",
        "\n",
        "for слово in примерные_слова:\n",
        "    if слово in модель.wv:\n",
        "        вектор = модель.wv[слово]\n",
        "        # Берем только первые 5 чисел\n",
        "        короткий_вектор = вектор[:5]\n",
        "        print(f\"\\n'{слово}': {короткий_вектор}\")\n",
        "        print(f\"  (и еще {len(вектор)-5} чисел...)\")"
      ],
      "metadata": {
        "id": "-ql25a3lYIWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d36468-5c26-432a-e13b-179e4241bd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создаю модель Word2Vec для анализа кулинарных текстов...\n",
            "Готово! Модель обучена.\n",
            "В словаре 65 кулинарных слов\n",
            "\n",
            "Слова из наших рецептов:\n",
            "• овощи\n",
            "• мясо\n",
            "• соус\n",
            "• вода\n",
            "• тесто\n",
            "• духовка\n",
            "• специи\n",
            "• варить\n",
            "• брокколи\n",
            "• питание\n",
            "• здоровое\n",
            "• парить\n",
            "• торт\n",
            "• десерт\n",
            "• сахар\n",
            "• сливки\n",
            "• взбивать\n",
            "• холодильник\n",
            "• мариновать\n",
            "• чашка\n",
            "• кофе\n",
            "• чай\n",
            "• кипятить\n",
            "• яблоки\n",
            "• начинка\n",
            "• пирог\n",
            "• месить\n",
            "• тост\n",
            "• бекон\n",
            "• яичница\n",
            "• завтрак\n",
            "• готовить\n",
            "• фольга\n",
            "• лимон\n",
            "• рыба\n",
            "• запекать\n",
            "• травы\n",
            "• вино\n",
            "• горшок\n",
            "• говядина\n",
            "• тушить\n",
            "• барбекю\n",
            "• уголь\n",
            "• гриль\n",
            "• соль\n",
            "• паста\n",
            "• молоко\n",
            "• яйца\n",
            "• ингредиенты\n",
            "• смешивать\n",
            "• огурцы\n",
            "• помидоры\n",
            "• салат\n",
            "• резать\n",
            "• дрожжи\n",
            "• мука\n",
            "• хлеб\n",
            "• печь\n",
            "• масло\n",
            "• сковорода\n",
            "• курица\n",
            "• жарить\n",
            "• картофель\n",
            "• морковь\n",
            "• суп\n",
            "\n",
            "----------------------------------------\n",
            "А теперь посмотрим на семантические связи:\n",
            "\n",
            "Что похоже на 'варить'?\n",
            "  вино (24.0% схожести)\n",
            "  ингредиенты (21.7% схожести)\n",
            "  хлеб (19.4% схожести)\n",
            "\n",
            "Что похоже на 'жарить'?\n",
            "  парить (31.1% схожести)\n",
            "  взбивать (30.9% схожести)\n",
            "  торт (27.0% схожести)\n",
            "\n",
            "Что похоже на 'резать'?\n",
            "  салат (30.6% схожести)\n",
            "  яйца (29.9% схожести)\n",
            "  гриль (25.5% схожести)\n",
            "\n",
            "Что похоже на 'печь'?\n",
            "  дрожжи (33.8% схожести)\n",
            "  десерт (24.3% схожести)\n",
            "  завтрак (22.2% схожести)\n",
            "\n",
            "----------------------------------------\n",
            "Сравним некоторые слова:\n",
            "  суп и салат: 0.01\n",
            "  духовка и сковорода: 0.10\n",
            "  овощи и фрукты: не можем сравнить\n",
            "\n",
            "----------------------------------------\n",
            "Векторное представление слов (первые 5 значений):\n",
            "\n",
            "'суп': [ 0.01283087 -0.01790228 -0.01469094 -0.00350229  0.00339602]\n",
            "  (и еще 45 чисел...)\n",
            "\n",
            "'овощи': [-0.00105995  0.00048835  0.01020287  0.01804369 -0.01858319]\n",
            "  (и еще 45 чисел...)\n",
            "\n",
            "'духовка': [ 0.00287342 -0.00529054 -0.01414675 -0.01560599 -0.01824353]\n",
            "  (и еще 45 чисел...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Слова в словаре: {list(model.wv.key_to_index.keys())[:10]}...\")"
      ],
      "metadata": {
        "id": "uC6KfmGuYUsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Проверьте модель"
      ],
      "metadata": {
        "id": "rUp76Ko3YYLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем похожие слова в кулинарной тематике\n",
        "try:\n",
        "    similar = model.wv.most_similar('варить', topn=5)\n",
        "    print(\"Слова, похожие на 'варить':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'варить' не найдено в словаре\")"
      ],
      "metadata": {
        "id": "NL21ZMMMYZqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем похожие слова в кулинарной тематике\n",
        "try:\n",
        "    similar = model.most_similar('варить', topn=5)  # Убрали .wv\n",
        "    print(\"Слова, похожие на 'варить':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'варить' не найдено в словаре\")\n",
        "except AttributeError:\n",
        "    # Если model.wv существует, используем его\n",
        "    try:\n",
        "        similar = model.wv.most_similar('варить', topn=5)\n",
        "        print(\"Слова, похожие на 'варить':\")\n",
        "        for word, score in similar:\n",
        "            print(f\"  {word}: {score:.4f}\")\n",
        "    except:\n",
        "        print(\"Ошибка при поиске похожих слов\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Найдем слова, похожие на \"духовка\"\n",
        "try:\n",
        "    # Пробуем оба варианта\n",
        "    try:\n",
        "        similar_duhovka = model.most_similar('духовка', topn=5)\n",
        "    except AttributeError:\n",
        "        similar_duhovka = model.wv.most_similar('духовка', topn=5)\n",
        "\n",
        "    print(\"Слова, похожие на 'духовка':\")\n",
        "    for word, score in similar_duhovka:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'духовка' не найдено в словаре\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Найдем слова, похожие на \"овощи\"\n",
        "try:\n",
        "    # Пробуем оба варианта\n",
        "    try:\n",
        "        similar_ovoschi = model.most_similar('овощи', topn=5)\n",
        "    except AttributeError:\n",
        "        similar_ovoschi = model.wv.most_similar('овощи', topn=5)\n",
        "\n",
        "    print(\"Слова, похожие на 'овощи':\")\n",
        "    for word, score in similar_ovoschi:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'овощи' не найдено в словаре\")"
      ],
      "metadata": {
        "id": "DZWc7eNVYcSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f4c99b-9c0f-42f3-f34f-0f6d67375319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'варить':\n",
            "  борщ: 0.9473\n",
            "  шить: 0.9186\n",
            "  жарить: 0.9179\n",
            "  готовить: 0.9172\n",
            "  челку: 0.9095\n",
            "\n",
            "==================================================\n",
            "Слово 'духовка' не найдено в словаре\n",
            "\n",
            "==================================================\n",
            "Слова, похожие на 'овощи':\n",
            "  фрукты: 0.9272\n",
            "  столы: 0.8663\n",
            "  курицу: 0.8606\n",
            "  носки: 0.8594\n",
            "  зеленые: 0.8577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2: FastText"
      ],
      "metadata": {
        "id": "i1JAFNQvYhAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastText улучшает Word2Vec, рассматривая слова как наборы символов (n-грамм). Это позволяет работать с редкими словами и опечатками"
      ],
      "metadata": {
        "id": "Z1tWdzB-Ysi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Обучите FastText на корпусе текстов из пункта 3. Используйте код ниже"
      ],
      "metadata": {
        "id": "79i4vH8NY-0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# Наши рецепты\n",
        "рецепты = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]\n",
        "\n",
        "# Обучаем FastText\n",
        "print(\"Учу модель FastText...\")\n",
        "ft_model = FastText(\n",
        "    sentences=рецепты,  # наши тексты\n",
        "    vector_size=50,     # размер вектора\n",
        "    window=3,           # смотрим на 3 слова вокруг\n",
        "    min_count=1,        # берем все слова\n",
        "    workers=2           # два потока\n",
        ")\n",
        "\n",
        "print(\"Готово! Модель обучена\")\n",
        "print(f\"Слов в словаре: {len(ft_model.wv)}\")\n",
        "print()\n",
        "\n",
        "# Проверим похожие слова\n",
        "print(\"Что похоже на 'варить'?\")\n",
        "if 'варить' in ft_model.wv:\n",
        "    похожие = ft_model.wv.most_similar('варить', topn=5)\n",
        "    for слово, балл in похожие:\n",
        "        print(f\"  {слово} ({балл:.3f})\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Особенность FastText: работает с неизвестными словами\n",
        "print(\"Особенность FastText:\")\n",
        "print(\"Может находить похожие слова, даже если их не было в текстах!\")\n",
        "\n",
        "# Слова, которых нет в исходных текстах\n",
        "новые_слова = ['варил', 'овощной', 'жарильня']\n",
        "\n",
        "for слово in новые_слова:\n",
        "    print(f\"\\nДля слова '{слово}' (его не было в текстах):\")\n",
        "    try:\n",
        "        похожие = ft_model.wv.most_similar(слово, topn=3)\n",
        "        for похожее_слово, балл in похожие:\n",
        "            print(f\"  {похожее_слово} ({балл:.3f})\")\n",
        "    except:\n",
        "        print(f\"  Не получилось найти похожие слова\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Еще примеры\n",
        "print(\"Еще примеры:\")\n",
        "\n",
        "слова_для_проверки = ['духовка', 'овощи', 'тесто']\n",
        "\n",
        "for слово in слова_для_проверки:\n",
        "    print(f\"\\nПохожие на '{слово}':\")\n",
        "    if слово in ft_model.wv:\n",
        "        похожие = ft_model.wv.most_similar(слово, topn=3)\n",
        "        for похожее_слово, балл in похожие:\n",
        "            print(f\"  {похожее_слово} ({балл:.3f})\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Сохраним модель\n",
        "ft_model.save(\"моя_кулинарная_модель.model\")\n",
        "print(\"Модель сохранена в файл 'моя_кулинарная_модель.model'\")"
      ],
      "metadata": {
        "id": "-IrOgMpQYuda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b016a6-ff2e-4ac3-a977-69bbcacda2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Учу модель FastText...\n",
            "Готово! Модель обучена\n",
            "Слов в словаре: 65\n",
            "\n",
            "Что похоже на 'варить'?\n",
            "  жарить (0.535)\n",
            "  парить (0.480)\n",
            "  месить (0.354)\n",
            "  тушить (0.340)\n",
            "  специи (0.262)\n",
            "\n",
            "----------------------------------------\n",
            "Особенность FastText:\n",
            "Может находить похожие слова, даже если их не было в текстах!\n",
            "\n",
            "Для слова 'варил' (его не было в текстах):\n",
            "  уголь (0.250)\n",
            "  варить (0.248)\n",
            "  ингредиенты (0.207)\n",
            "\n",
            "Для слова 'овощной' (его не было в текстах):\n",
            "  овощи (0.379)\n",
            "  суп (0.257)\n",
            "  десерт (0.226)\n",
            "\n",
            "Для слова 'жарильня' (его не было в текстах):\n",
            "  торт (0.335)\n",
            "  гриль (0.233)\n",
            "  ингредиенты (0.219)\n",
            "\n",
            "----------------------------------------\n",
            "Еще примеры:\n",
            "\n",
            "Похожие на 'духовка':\n",
            "  взбивать (0.457)\n",
            "  лимон (0.356)\n",
            "  салат (0.305)\n",
            "\n",
            "Похожие на 'овощи':\n",
            "  жарить (0.296)\n",
            "  фольга (0.257)\n",
            "  морковь (0.230)\n",
            "\n",
            "Похожие на 'тесто':\n",
            "  гриль (0.341)\n",
            "  яблоки (0.327)\n",
            "  сковорода (0.311)\n",
            "\n",
            "----------------------------------------\n",
            "Модель сохранена в файл 'моя_кулинарная_модель.model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Найдите слова, похожие на \"варить\", \"духовка\" и \"овощи\" с помощью обученной модели. Используйте код из пункта 4"
      ],
      "metadata": {
        "id": "JBTW3zDPZIIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем нашу модель\n",
        "\n",
        "print(\"Что наша модель думает о словах?\")\n",
        "print()\n",
        "\n",
        "# 1. Для слова \"варить\"\n",
        "print(\"1. Что похоже на 'варить'?\")\n",
        "похожие_на_варить = ft_model.wv.most_similar('варить', topn=5)\n",
        "for слово, как_похоже in похожие_на_варить:\n",
        "    # Переводим в проценты для понятности\n",
        "    проценты = как_похоже * 100\n",
        "    print(f\"{слово} ({проценты:.1f}% похоже)\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 2. Для слова \"духовка\"\n",
        "print(\"2. Что похоже на 'духовка'?\")\n",
        "похожие_на_духовка = ft_model.wv.most_similar('духовка', topn=5)\n",
        "for слово, как_похоже in похожие_на_духовка:\n",
        "    проценты = как_похоже * 100\n",
        "    print(f\"{слово} ({проценты:.1f}% похоже)\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 3. Для слова \"овощи\"\n",
        "print(\"3. Что похоже на 'овощи'?\")\n",
        "похожие_на_овощи = ft_model.wv.most_similar('овощи', topn=5)\n",
        "for слово, как_похоже in похожие_на_овощи:\n",
        "    проценты = как_похоже * 100\n",
        "    print(f\"{слово} ({проценты:.1f}% похоже)\")"
      ],
      "metadata": {
        "id": "ouc0CcZAY6QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb3a7f8-280f-4598-bf1c-1fe90f24760b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Что наша модель думает о словах?\n",
            "\n",
            "1. Что похоже на 'варить'?\n",
            "жарить (53.5% похоже)\n",
            "парить (48.0% похоже)\n",
            "месить (35.4% похоже)\n",
            "тушить (34.0% похоже)\n",
            "специи (26.2% похоже)\n",
            "\n",
            "------------------------------\n",
            "2. Что похоже на 'духовка'?\n",
            "взбивать (45.7% похоже)\n",
            "лимон (35.6% похоже)\n",
            "салат (30.5% похоже)\n",
            "курица (30.4% похоже)\n",
            "тост (29.4% похоже)\n",
            "\n",
            "------------------------------\n",
            "3. Что похоже на 'овощи'?\n",
            "жарить (29.6% похоже)\n",
            "фольга (25.7% похоже)\n",
            "морковь (23.0% похоже)\n",
            "соус (21.7% похоже)\n",
            "торт (20.9% похоже)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3S46N8cyg-Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Сравните модели\n",
        "\n",
        "Дана функция для сравнения Word2Vec и FastText\n",
        "\n",
        "Придумайте 3 слова с опечатками и проверьте, найдет ли их FastText и Word2Vec"
      ],
      "metadata": {
        "id": "vm8kkRlBZYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравнение моделей\n",
        "print(\"Проверим, как модели справляются с опечатками\\n\")\n",
        "\n",
        "# Наши слова с ошибками\n",
        "слова_с_ошибками = [\n",
        "    ('варить', 'варитть'),      # лишняя буква\n",
        "    ('духовка', 'духовкa'),     # латинская буква\n",
        "    ('овощи', 'авощи'),         # не та первая буква\n",
        "    ('сковорода', 'скаворода'), # переставлены буквы\n",
        "]\n",
        "\n",
        "for правильное, с_ошибкой in слова_с_ошибками:\n",
        "    print(f\"\\nСлово с ошибкой: '{с_ошибкой}' (должно быть '{правильное}')\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Word2Vec\n",
        "    try:\n",
        "        # Пробуем найти в Word2Vec\n",
        "        w2v_результат = model.wv.most_similar(с_ошибкой, topn=2)\n",
        "        print(f\"  Word2Vec: нашёл {[w for w, _ in w2v_результат]}\")\n",
        "    except:\n",
        "        print(f\"  Word2Vec: не нашёл такое слово\")\n",
        "\n",
        "    # FastText\n",
        "    try:\n",
        "        # Пробуем найти в FastText\n",
        "        ft_результат = ft_model.wv.most_similar(с_ошибкой, topn=2)\n",
        "        print(f\"  FastText: нашёл {[w for w, _ in ft_результат]}\")\n",
        "    except:\n",
        "        print(f\"  FastText: не нашёл такое слово\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ВЫВОД: FastText лучше справляется с опечатками!\")\n",
        "print(\"Потому что он смотрит на части слов, а не на слова целиком.\")"
      ],
      "metadata": {
        "id": "3nVH_v9WZY4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0718dc1b-5515-4bd3-e508-0f6079e05cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверим, как модели справляются с опечатками\n",
            "\n",
            "\n",
            "Слово с ошибкой: 'варитть' (должно быть 'варить')\n",
            "----------------------------------------\n",
            "  Word2Vec: не нашёл такое слово\n",
            "  FastText: нашёл ['варить', 'печь']\n",
            "\n",
            "Слово с ошибкой: 'духовкa' (должно быть 'духовка')\n",
            "----------------------------------------\n",
            "  Word2Vec: не нашёл такое слово\n",
            "  FastText: нашёл ['духовка', 'взбивать']\n",
            "\n",
            "Слово с ошибкой: 'авощи' (должно быть 'овощи')\n",
            "----------------------------------------\n",
            "  Word2Vec: не нашёл такое слово\n",
            "  FastText: нашёл ['овощи', 'фольга']\n",
            "\n",
            "Слово с ошибкой: 'скаворода' (должно быть 'сковорода')\n",
            "----------------------------------------\n",
            "  Word2Vec: не нашёл такое слово\n",
            "  FastText: нашёл ['сковорода', 'горшок']\n",
            "\n",
            "==================================================\n",
            "ВЫВОД: FastText лучше справляется с опечатками!\n",
            "Потому что он смотрит на части слов, а не на слова целиком.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 3: Doc2Vec"
      ],
      "metadata": {
        "id": "DP62ewZzZoGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec расширяет Word2Vec для создания векторных представлений целых документов (предложений, абзацев, статей)"
      ],
      "metadata": {
        "id": "tG1GNzXcZqOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем размеченные документы\n",
        "documents = [\n",
        "    \"machine learning is interesting\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"python programming for data science\",\n",
        "    \"artificial intelligence is amazing\",\n",
        "    \"computer vision processes images\"\n",
        "]\n",
        "\n",
        "# Преобразуем в формат TaggedDocument\n",
        "tagged_docs = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()\n",
        "    tagged_doc = TaggedDocument(words=tokens, tags=[f\"doc_{i}\"])\n",
        "    tagged_docs.append(tagged_doc)\n",
        "\n",
        "print(\"Размеченные документы:\")\n",
        "for doc in tagged_docs[:3]:\n",
        "    print(f\"  Слова: {doc.words}\")\n",
        "    print(f\"  Тег: {doc.tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85mtFa_ZxoY",
        "outputId": "3db49b66-bdf0-464b-9dc4-3ce60c7f9e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеченные документы:\n",
            "  Слова: ['machine', 'learning', 'is', 'interesting']\n",
            "  Тег: ['doc_0']\n",
            "  Слова: ['deep', 'learning', 'uses', 'neural', 'networks']\n",
            "  Тег: ['doc_1']\n",
            "  Слова: ['python', 'programming', 'for', 'data', 'science']\n",
            "  Тег: ['doc_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем Doc2Vec\n",
        "doc_model = Doc2Vec(\n",
        "    documents=tagged_docs,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "print(\"Doc2Vec модель обучена!\")\n",
        "print(f\"Количество документов: {len(doc_model.dv.key_to_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJ1vOcHZx0z",
        "outputId": "bc20b9ed-2069-47a8-bd35-2890d9411f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc2Vec модель обучена!\n",
            "Количество документов: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор документа\n",
        "doc_vector = doc_model.dv[\"doc_0\"]\n",
        "print(f\"Вектор документа doc_0: {doc_vector[:5]}...\")\n",
        "\n",
        "# Находим похожие документы\n",
        "similar_docs = doc_model.dv.most_similar(\"doc_0\", topn=2)\n",
        "print(\"\\nДокументы, похожие на doc_0:\")\n",
        "for doc_tag, similarity in similar_docs:\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "    print(f\"  {doc_tag}: {similarity:.4f}\")\n",
        "    print(f\"    Текст: {documents[doc_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x8vHn0bZ0Ow",
        "outputId": "3bd645d5-30da-433f-cfa2-0598c3641951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор документа doc_0: [-0.01057    -0.01198188 -0.01982618  0.01710627  0.00710373]...\n",
            "\n",
            "Документы, похожие на doc_0:\n",
            "  doc_1: 0.2735\n",
            "    Текст: deep learning uses neural networks\n",
            "  doc_2: 0.1275\n",
            "    Текст: python programming for data science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравниваем схожесть документов\n",
        "def compare_documents(doc1_id, doc2_id):\n",
        "    similarity = doc_model.dv.similarity(f\"doc_{doc1_id}\", f\"doc_{doc2_id}\")\n",
        "    print(f\"Схожесть doc_{doc1_id} и doc_{doc2_id}: {similarity:.4f}\")\n",
        "    print(f\"  doc_{doc1_id}: {documents[doc1_id]}\")\n",
        "    print(f\"  doc_{doc2_id}: {documents[doc2_id]}\")\n",
        "\n",
        "compare_documents(0, 1)  # machine learning vs deep learning\n",
        "compare_documents(0, 3)  # machine learning vs AI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfjR2xZZ1rC",
        "outputId": "510c722d-2eb8-4ef2-c3fc-3c9436fcbe10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_0 и doc_1: 0.2735\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_1: deep learning uses neural networks\n",
            "Схожесть doc_0 и doc_3: -0.0822\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_3: artificial intelligence is amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Сравните схожесть doc_2 и doc_4"
      ],
      "metadata": {
        "id": "1ruGP7-vZ6HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Наши рецепты\n",
        "рецепты = [\n",
        "    \"варить суп овощи\",\n",
        "    \"жарить курица масло\",\n",
        "    \"печь хлеб духовка\",\n",
        "    \"резать овощи салат\",\n",
        "    \"смешивать тесто яйца\"\n",
        "]\n",
        "\n",
        "# 1. Подготавливаем документы\n",
        "подготовленные_документы = []\n",
        "for i, текст in enumerate(рецепты):\n",
        "    слова = текст.split()\n",
        "    документ = TaggedDocument(words=слова, tags=[f\"doc_{i}\"])\n",
        "    подготовленные_документы.append(документ)\n",
        "\n",
        "# 2. Обучаем модель\n",
        "модель = Doc2Vec(\n",
        "    documents=подготовленные_документы,\n",
        "    vector_size=50,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "print(\"Модель Doc2Vec готова!\")\n",
        "print(f\"Обучили на {len(модель.dv)} документах\\n\")\n",
        "\n",
        "# 3. Сравниваем doc_2 и doc_4\n",
        "print(\"Сравниваем doc_2 и doc_4:\")\n",
        "print(f\"doc_2: {рецепты[2]}\")\n",
        "print(f\"doc_4: {рецепты[4]}\")\n",
        "\n",
        "# Считаем схожесть\n",
        "схожесть = модель.dv.similarity(\"doc_2\", \"doc_4\")\n",
        "print(f\"\\nСхожесть: {схожесть:.3f}\")\n",
        "\n",
        "# Объясняем результат\n",
        "if схожесть > 0.5:\n",
        "    print(\"Документы довольно похожи!\")\n",
        "else:\n",
        "    print(\"Документы не очень похожи.\")"
      ],
      "metadata": {
        "id": "LujlVE8aZ3fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd321238-5801-4ea7-ed9b-6d2bd47d8452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель Doc2Vec готова!\n",
            "Обучили на 5 документах\n",
            "\n",
            "Сравниваем doc_2 и doc_4:\n",
            "doc_2: печь хлеб духовка\n",
            "doc_4: смешивать тесто яйца\n",
            "\n",
            "Схожесть: -0.042\n",
            "Документы не очень похожи.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Найдите самый похожий документ на doc_1"
      ],
      "metadata": {
        "id": "YkW4U8T_Z_X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Сначала создадим документы\n",
        "documents = [\n",
        "    \"варить суп овощи морковь картофель\",\n",
        "    \"жарить курица сковорода масло специи\",\n",
        "    \"печь хлеб мука дрожжи духовка\",\n",
        "    \"резать овощи салат помидоры огурцы\",\n",
        "    \"смешивать ингредиенты тесто яйца молоко\",\n",
        "    \"варить паста вода соль соус\",\n",
        "    \"гриль мясо овощи уголь барбекю\",\n",
        "    \"тушить говядина горшок вино травы\",\n",
        "    \"запекать рыба лимон духовка фольга\",\n",
        "    \"готовить завтрак яичница бекон тост\"\n",
        "]\n",
        "\n",
        "# Создаем размеченные документы\n",
        "tagged_docs = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()\n",
        "    tagged_doc = TaggedDocument(words=tokens, tags=[f\"doc_{i}\"])\n",
        "    tagged_docs.append(tagged_doc)\n",
        "\n",
        "# Обучаем модель\n",
        "print(\"Обучаю модель Doc2Vec...\")\n",
        "doc_model = Doc2Vec(\n",
        "    documents=tagged_docs,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "print(\"Модель обучена!\\n\")\n",
        "\n",
        "# Теперь ищем самый похожий документ на doc_1\n",
        "print(\"=\" * 50)\n",
        "print(\"Ищем самый похожий документ на doc_1\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Что такое doc_1?\n",
        "print(f\"doc_1: '{documents[1]}'\")\n",
        "print()\n",
        "\n",
        "# Ищем похожие документы\n",
        "print(\"Похожие документы на doc_1:\")\n",
        "similar_docs = doc_model.dv.most_similar(\"doc_1\", topn=len(documents))\n",
        "\n",
        "# Показываем результаты\n",
        "for i in range(1, min(4, len(similar_docs))):  # Покажем первые 3 (начиная со второго)\n",
        "    doc_tag, similarity = similar_docs[i]\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "\n",
        "    print(f\"\\n{i}. {doc_tag}: {similarity:.3f}\")\n",
        "    print(f\"   '{documents[doc_id]}'\")\n",
        "\n",
        "# Самый похожий документ\n",
        "most_similar_tag, most_similar_score = similar_docs[1]\n",
        "most_similar_id = int(most_similar_tag.split('_')[1])\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"САМЫЙ ПОХОЖИЙ ДОКУМЕНТ НА doc_1:\")\n",
        "print(f\"doc_{most_similar_id} (схожесть: {most_similar_score:.3f})\")\n",
        "print(f\"Текст: '{documents[most_similar_id]}'\")"
      ],
      "metadata": {
        "id": "T0IwRpOPaGX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1308a823-19ba-4a7d-bab5-b632e37c0b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаю модель Doc2Vec...\n",
            "Модель обучена!\n",
            "\n",
            "==================================================\n",
            "Ищем самый похожий документ на doc_1\n",
            "==================================================\n",
            "doc_1: 'жарить курица сковорода масло специи'\n",
            "\n",
            "Похожие документы на doc_1:\n",
            "\n",
            "1. doc_0: 0.274\n",
            "   'варить суп овощи морковь картофель'\n",
            "\n",
            "2. doc_5: 0.249\n",
            "   'варить паста вода соль соус'\n",
            "\n",
            "3. doc_3: 0.204\n",
            "   'резать овощи салат помидоры огурцы'\n",
            "\n",
            "========================================\n",
            "САМЫЙ ПОХОЖИЙ ДОКУМЕНТ НА doc_1:\n",
            "doc_0 (схожесть: 0.274)\n",
            "Текст: 'варить суп овощи морковь картофель'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Выберите любую из трёх моделей. Обучите модели с разной размерностью (10, 50, 100). Продемонстрируйте качество их работы на примере поиска похожих слов (выберите любые 3 примера, соответствующих тематике корпуса из пункта 4)"
      ],
      "metadata": {
        "id": "GHoOQmGraGmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# Данные\n",
        "рецепты = [\n",
        "    ['варить', 'суп', 'овощи'],\n",
        "    ['жарить', 'курица', 'масло'],\n",
        "    ['печь', 'хлеб', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат']\n",
        "]\n",
        "\n",
        "print(\"Сравниваем три модели FastText:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Обучаем три модели\n",
        "модели = {}\n",
        "размерности = [10, 50, 100]\n",
        "\n",
        "for размер in размерности:\n",
        "    print(f\"\\nМодель с размерностью {размер}:\")\n",
        "    модель = FastText(рецепты, vector_size=размер, min_count=1)\n",
        "    модели[размер] = модель\n",
        "    print(f\"  Обучена! Слов: {len(модель.wv)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"Тестируем на слове 'варить':\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "for размер in размерности:\n",
        "    модель = модели[размер]\n",
        "\n",
        "    print(f\"\\nРазмерность {размер}:\")\n",
        "    if 'варить' in модель.wv:\n",
        "        похожие = модель.wv.most_similar('варить', topn=2)\n",
        "        for слово, оценка in похожие:\n",
        "            проценты = оценка * 100\n",
        "            print(f\"  {слово} ({проценты:.1f}%)\")\n",
        "    else:\n",
        "        print(\"  Слово не найдено\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"Тестируем на слове 'духовка':\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "for размер in размерности:\n",
        "    модель = модели[размер]\n",
        "\n",
        "    print(f\"\\nРазмерность {размер}:\")\n",
        "    if 'духовка' in модель.wv:\n",
        "        похожие = модель.wv.most_similar('духовка', topn=2)\n",
        "        for слово, оценка in похожие:\n",
        "            проценты = оценка * 100\n",
        "            print(f\"  {слово} ({проценты:.1f}%)\")"
      ],
      "metadata": {
        "id": "tidpF7AIaXzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d8ff27-4ed1-4045-c7e5-6b532a8f1d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сравниваем три модели FastText:\n",
            "========================================\n",
            "\n",
            "Модель с размерностью 10:\n",
            "  Обучена! Слов: 11\n",
            "\n",
            "Модель с размерностью 50:\n",
            "  Обучена! Слов: 11\n",
            "\n",
            "Модель с размерностью 100:\n",
            "  Обучена! Слов: 11\n",
            "\n",
            "========================================\n",
            "Тестируем на слове 'варить':\n",
            "========================================\n",
            "\n",
            "Размерность 10:\n",
            "  печь (39.4%)\n",
            "  жарить (35.9%)\n",
            "\n",
            "Размерность 50:\n",
            "  жарить (56.1%)\n",
            "  резать (30.5%)\n",
            "\n",
            "Размерность 100:\n",
            "  жарить (57.7%)\n",
            "  салат (10.5%)\n",
            "\n",
            "========================================\n",
            "Тестируем на слове 'духовка':\n",
            "========================================\n",
            "\n",
            "Размерность 10:\n",
            "  жарить (61.0%)\n",
            "  овощи (56.7%)\n",
            "\n",
            "Размерность 50:\n",
            "  салат (25.3%)\n",
            "  масло (21.9%)\n",
            "\n",
            "Размерность 100:\n",
            "  жарить (14.2%)\n",
            "  варить (6.2%)\n"
          ]
        }
      ]
    }
  ]
}